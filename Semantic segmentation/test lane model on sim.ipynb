{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271b03a5",
   "metadata": {},
   "source": [
    "This is to test lane model on sim situation in difficult conditions\n",
    "First we need to generate images \n",
    "We need to use python env with Carla 9.13 to avoid the bug for Windows images in 9.14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e86e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports\n",
    "import carla #the sim library itself\n",
    "import random #to pick random spawn point\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b980b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the sim \n",
    "client = carla.Client('localhost', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a map with challenging road without lane marking\n",
    "#client.set_timeout(15)\n",
    "client.load_world('Town04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move in the sim window to find a road with just kurbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328c9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b475c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08474862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform(Location(x=162.145157, y=-312.076935, z=5.093169), Rotation(pitch=-20.583956, yaw=169.282288, roll=0.000074))\n"
     ]
    }
   ],
   "source": [
    "print(spectator.get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4358da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform(Location(x=195.500870, y=-311.011993, z=1.500359), Rotation(pitch=-1.347439, yaw=174.997467, roll=0.000115))\n"
     ]
    }
   ],
   "source": [
    "# move to the start of that street\n",
    "print(spectator.get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc05a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_manager = client.get_trafficmanager(8000)\n",
    "\n",
    "blueprints = world.get_blueprint_library().filter('*vehicle*')\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "# clean up\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "settings.no_rendering_mode = False\n",
    "traffic_manager.set_synchronous_mode(True)\n",
    "traffic_manager.global_percentage_speed_difference(70)\n",
    "\n",
    "world.apply_settings(settings)\n",
    "    \n",
    "vehicle = world.try_spawn_actor(vehicle_bp[0], random.choice(spawn_points))\n",
    "# generate traffic limited number\n",
    "counter = 0\n",
    "traffic = []\n",
    "random.shuffle(spawn_points)\n",
    "for n, transform in enumerate(spawn_points):\n",
    "    counter +=1\n",
    "    if counter > len(spawn_points)/3: # good volume of traffic - up to 1/3 of available spawn points\n",
    "        break\n",
    "    blueprint = random.choice(blueprints)\n",
    "    traffic_vehicle = world.try_spawn_actor(blueprint, transform)\n",
    "    if traffic_vehicle != None:# spawn the cars and set their autopilot and light state all together\n",
    "        traffic.append(traffic_vehicle)\n",
    "        traffic_vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "        traffic_vehicle.set_autopilot(True)\n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "    \n",
    "def rgb_callback(image,data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "if vehicle == None:\n",
    "    print(\"Re-start the sim\")\n",
    "else:\n",
    "    #lights always on\n",
    "    vehicle.set_transform(carla.Transform(carla.Location(x=195.500870, y=-311.011993, z=1.500359),carla.Rotation(yaw=180)))\n",
    "    vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "    vehicle.set_autopilot(True)\n",
    "    \n",
    "    #camera mount offset on the car - you can tweak these to each car to avoid any parts of the car being in the view\n",
    "    CAMERA_POS_Z = 1.3 \n",
    "    CAMERA_POS_X = 1.4 \n",
    "\n",
    "    #normal rgb camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_rgb = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "\n",
    "    image_w = 640\n",
    "    image_h = 480\n",
    "\n",
    "    camera_data = {'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "    # this actually opens a live stream from the cameras\n",
    "    camera_rgb.listen(lambda image: rgb_callback(image,camera_data))\n",
    "    # get all drivable locations on the map\n",
    "    all_roads = world.get_map().get_topology()\n",
    "    #loop 1 time of day dry\n",
    "    weather = carla.WeatherParameters(\n",
    "            cloudiness=99,\n",
    "            precipitation=80,\n",
    "            sun_altitude_angle=10,\n",
    "            precipitation_deposits =100,\n",
    "            fog_density =0.9,\n",
    "            wetness = 75)\n",
    "    world.set_weather(weather)\n",
    "    img_counter = 0\n",
    "    prev_position = vehicle.get_transform()\n",
    "    while img_counter < 200:\n",
    "        world.tick()\n",
    "        current_position = vehicle.get_transform()\n",
    "        rgb_im = camera_data['rgb_image']\n",
    "       \n",
    "        cv2.imshow('2 cameras', rgb_im)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        #write images\n",
    "        if current_position.location.distance(prev_position.location)>1:\n",
    "            prev_position = current_position\n",
    "            img_counter += 1\n",
    "            time_grab = time.time_ns()\n",
    "            cv2.imwrite('C:/SelfDrive/Semantic segmentation/test/%06d.png' % time_grab, rgb_im)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_rgb.stop() \n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63acf2e4",
   "metadata": {},
   "source": [
    "Now we have generated images in 'C:/SelfDrive/Semantic segmentation/test/\n",
    "\n",
    "Now we need to switch to tf2 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17647bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenging case\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt #to show images in this notebook\n",
    "\n",
    "NAME = \"UNET_LANES_WCE_LOSS-1680304258\"\n",
    "model = load_model(\"model/{}\".format(NAME),compile=False)\n",
    "\n",
    "\n",
    "rgb_path = 'C:/SelfDrive/Semantic segmentation/test/'\n",
    "rgb_images = os.listdir(rgb_path)\n",
    "\n",
    "for pth in rgb_images: \n",
    "    rgb_img = cv2.imread(rgb_path+pth,cv2.IMREAD_COLOR)\n",
    "    img = np.float32(rgb_img /255)\n",
    "    input_for_model = img[ :, :, None] \n",
    "    input_for_model = np.expand_dims(img, axis=0)\n",
    "    mask = model(input_for_model,training=False)\n",
    "    final_mask = (np.squeeze(mask[0].numpy()) * 255)\n",
    "    gray = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n",
    "    result = cv2.bitwise_and(gray,gray,mask = final_mask.astype(np.uint8))\n",
    "    cv2.imshow('predicted mask',result)\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(250) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08a60dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all original images\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt #to show images in this notebook\n",
    "\n",
    "NAME = \"UNET_LANES_WCE_LOSS-1680304258\"\n",
    "model = load_model(\"model/{}\".format(NAME),compile=False)\n",
    "\n",
    "\n",
    "rgb_path = 'C:/SelfDrive/out_sem/rgb/'\n",
    "rgb_images = os.listdir(rgb_path)\n",
    "\n",
    "for pth in rgb_images: \n",
    "    rgb_img = cv2.imread(rgb_path+pth,cv2.IMREAD_COLOR)\n",
    "    img = np.float32(rgb_img /255)\n",
    "    input_for_model = img[ :, :, None] \n",
    "    input_for_model = np.expand_dims(img, axis=0)\n",
    "    mask = model(input_for_model,training=False)\n",
    "    final_mask = (np.squeeze(mask[0].numpy()) * 255)\n",
    "    gray = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n",
    "    result = cv2.bitwise_and(gray,gray,mask = final_mask.astype(np.uint8))\n",
    "    cv2.imshow('predicted mask',result)\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(250) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88307fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
